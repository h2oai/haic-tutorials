{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end workflow in the H2O AI Cloud\n",
    "\n",
    "Get started building and deploying machine learning models in the H2O AI Cloud.\n",
    "\n",
    "* Create an AI engine for building models\n",
    "* Use AutoML to build a machine learning model\n",
    "* Deploy the model to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AI engine\n",
    "Create a Driverless AI engine for access to automated machine learning to build models for us on our data. \n",
    "\n",
    "See the `2 Managing AI Engines` tutorial for more details on how to use and interact with **Engine Manager** for creating and managing your AI Engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h2o_authn\n",
    "import h2o_discovery\n",
    "import h2o_engine_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery = h2o_discovery.discover()\n",
    "\n",
    "token_provider = h2o_authn.TokenProvider(\n",
    "    refresh_token=os.getenv(\"H2O_CLOUD_CLIENT_PLATFORM_TOKEN\"),\n",
    "    issuer_url=discovery.environment.issuer_url,\n",
    "    client_id=discovery.clients[\"platform\"].oauth2_client_id,\n",
    ")\n",
    "\n",
    "engine_manager = h2o_engine_manager.login(token_provider=token_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new engine can take 2-20 minutes depending on your environment and configuration settings. Please reach out to your admin as needed to reduce start times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dai_engine = engine_manager.dai_engine_client.create_engine(\n",
    "    display_name=\"My test engine\",\n",
    ")\n",
    "\n",
    "dai_engine.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4642c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dai = dai_engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 100.00% - [4/4] Computed stats for column Churn?\n"
     ]
    }
   ],
   "source": [
    "telco_churn = dai.datasets.create(\n",
    "    data=\"https://h2o-internal-release.s3-us-west-2.amazonaws.com/data/Splunk/churn.csv\",  \n",
    "    data_source=\"s3\", \n",
    "    name=\"Telco_Churn\",\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b34aade4-fcc5-11ec-bbbf-8af6970414ab | Telco_Churn\n",
      "\n",
      "Columns: ['State', 'Account Length', 'Area Code', 'Phone', \"Int'l Plan\", 'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge', 'CustServ Calls', 'Churn?']\n",
      "\n",
      "Shape: (3333, 21)\n"
     ]
    }
   ],
   "source": [
    "print(telco_churn.key, \"|\", telco_churn.name)\n",
    "print(\"\\nColumns:\", telco_churn.columns)\n",
    "print('\\nShape:', telco_churn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an AutoML experiment\n",
    "\n",
    "See the `3 AutoML` tutorial for more details on how to use and interact with Driverless AI for AutoML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_baseline = dai.experiments.create(\n",
    "    name='Default Baseline', \n",
    "    train_dataset=telco_churn, \n",
    "    target_column=\"Churn?\", \n",
    "    task=\"classification\",\n",
    "    accuracy=1, time=1, interpretability=6  # a quick AutoML experiment to see a baseline    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Complete\n",
      "Experiment: Default Baseline (bc7539d4-fcc5-11ec-bbbf-8af6970414ab)\n",
      "  Version: 1.10.3, 2022-07-06 00:53\n",
      "  Settings: 1/1/6, seed=6190721, GPUs enabled\n",
      "  Train data: Telco_Churn (3333, 21)\n",
      "  Validation data: N/A\n",
      "  Test data: N/A\n",
      "  Target column: Churn? (binary, 14.491% target class)\n",
      "System specs: Docker/Linux, 54 GB, 32 CPU cores, 1/1 GPU\n",
      "  Max memory usage: 0.763 GB, 0 GB GPU\n",
      "Recipe: AutoDL (5 iterations, 2 individuals)\n",
      "  Validation scheme: stratified, 1 internal holdout\n",
      "  Feature engineering: 28 features scored (19 selected)\n",
      "Timing: MOJO latency 0.0399 millis (214.2kB), Python latency 84.1064 millis (141.1kB)\n",
      "  Data preparation: 15.50 secs\n",
      "  Shift/Leakage detection: 1.18 secs\n",
      "  Model and feature tuning: 17.01 secs (6 models trained)\n",
      "  Feature evolution: 1.30 secs (0 of 3 model trained)\n",
      "  Final pipeline training: 26.99 secs (7 models trained)\n",
      "  Python / MOJO scorer building: 36.72 secs / 15.54 secs\n",
      "Validation score: LOGLOSS = 0.4137853 (constant preds of -1.775)\n",
      "Validation score: LOGLOSS = 0.3111744 +/- 0.0127315 (baseline)\n",
      "Validation score: LOGLOSS = 0.1618368 +/- 0.01040678 (final pipeline)\n",
      "Test score:       LOGLOSS = N/A\n"
     ]
    }
   ],
   "source": [
    "default_baseline.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project\n",
    "We willl create a project for our use case to easily share our work with others and deploy the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_project = dai.projects.create(\n",
    "    name=\"Telco Churn Predictions\", \n",
    "    description=\"Which of our customers is likely to cancel their contract?\",\n",
    "    force=\"True\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<driverlessai._projects.Project at 0x110df63a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_project.link_experiment(default_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MLOps\n",
    "See the `5 Model Deployment` tutorial for more details on how to use and interact with MLOps for managing models and deploymnets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o_mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlops = h2o_mlops.Client(\n",
    "    gateway_url=discovery.services['mlops-api'].uri,\n",
    "    token_provider=token_provider\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ba7c218-8065-4e11-a819-c3bcbb991e1f DEV\n",
      "9ad0c266-5913-4616-9057-9daa3188252f PROD\n"
     ]
    }
   ],
   "source": [
    "my_project_deployment_environments = mlops.storage.deployment_environment.list_deployment_environments(body={\n",
    "    'project_id': churn_project.key, \n",
    "}).deployment_environment\n",
    "\n",
    "for de in my_project_deployment_environments:\n",
    "    print(de.id, de.display_name)\n",
    "    if de.display_name == \"DEV\":\n",
    "        deployment_env = de.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_model_deployed = mlops.storage.deployment_environment.deploy({\n",
    "    'deployment_environment_id': de.id,\n",
    "    'experiment_id': default_baseline.key,\n",
    "    'type': 'SINGLE_MODEL'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View information about our deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deployment_id': '',\n",
       " 'grafana_endpoint': '',\n",
       " 'last_modified_time': None,\n",
       " 'message': '',\n",
       " 'scorer': None,\n",
       " 'state': 'DEPLOYMENT_STATE_UNSPECIFIED'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlops.deployer.deployment_status.get_deployment_status({\n",
    "    'deployment_id': churn_model_deployed.deployment.id\n",
    "}).deployment_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for deployment to become healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deployment_id': '7b695155-de7e-4b27-b219-48d150ab6930',\n",
       " 'grafana_endpoint': 'https://mlops-monitoring.cloud.h2o.ai/d/7b695155-de7e-4b27-b219-48d150ab6930',\n",
       " 'last_modified_time': datetime.datetime(2022, 7, 6, 0, 57, 29, tzinfo=tzutc()),\n",
       " 'message': 'N/A',\n",
       " 'scorer': {'capabilities': {'method': 'GET',\n",
       "                             'url': 'https://model.cloud.h2o.ai/7b695155-de7e-4b27-b219-48d150ab6930/model/capabilities'},\n",
       "            'sample_request': {'method': 'GET',\n",
       "                               'url': 'https://model.cloud.h2o.ai/7b695155-de7e-4b27-b219-48d150ab6930/model/sample_request'},\n",
       "            'score': {'method': 'POST',\n",
       "                      'url': 'https://model.cloud.h2o.ai/7b695155-de7e-4b27-b219-48d150ab6930/model/score'},\n",
       "            'type': 'MOJO2_REST_SCORER'},\n",
       " 'state': 'HEALTHY'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "deployment_status = mlops.deployer.deployment_status.get_deployment_status({\n",
    "        'deployment_id': churn_model_deployed.deployment.id\n",
    "    }).deployment_status.state\n",
    "\n",
    "while deployment_status != \"HEALTHY\":\n",
    "    time.sleep(5)\n",
    "    \n",
    "    deployment_status = mlops.deployer.deployment_status.get_deployment_status({\n",
    "        'deployment_id': churn_model_deployed.deployment.id\n",
    "    }).deployment_status.state\n",
    "    \n",
    "mlops.deployer.deployment_status.get_deployment_status({\n",
    "    'deployment_id': churn_model_deployed.deployment.id\n",
    "}).deployment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_request = mlops.deployer.deployment_status.get_deployment_status({\n",
    "    'deployment_id': churn_model_deployed.deployment.id\n",
    "}).deployment_status.scorer.sample_request.url\n",
    "\n",
    "\n",
    "deployment_url = mlops.deployer.deployment_status.get_deployment_status({\n",
    "    'deployment_id': churn_model_deployed.deployment.id\n",
    "}).deployment_status.scorer.score.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a prediction with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['State',\n",
       "  'Account Length',\n",
       "  'Area Code',\n",
       "  \"Int'l Plan\",\n",
       "  'VMail Plan',\n",
       "  'VMail Message',\n",
       "  'Day Mins',\n",
       "  'Day Calls',\n",
       "  'Day Charge',\n",
       "  'Eve Mins',\n",
       "  'Eve Calls',\n",
       "  'Eve Charge',\n",
       "  'Night Mins',\n",
       "  'Night Calls',\n",
       "  'Night Charge',\n",
       "  'Intl Mins',\n",
       "  'Intl Calls',\n",
       "  'Intl Charge',\n",
       "  'CustServ Calls'],\n",
       " 'rows': [['text',\n",
       "   '0',\n",
       "   '0',\n",
       "   'text',\n",
       "   'text',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0']]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_request_as_text = requests.get(sample_request).text\n",
    "sample_request = json.loads(sample_request_as_text)\n",
    "sample_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['Churn?.False.', 'Churn?.True.'],\n",
       " 'id': 'bc7539d4-fcc5-11ec-bbbf-8af6970414ab',\n",
       " 'score': [['0.96486217', '0.035137847']]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = requests.post(\n",
    "    url=deployment_url,\n",
    "    json={\n",
    "        'fields': sample_request[\"fields\"],\n",
    "        'rows': sample_request[\"rows\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "predictions = json.loads(new_predictions.text)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Percent: 3.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Churn Percent: {round(float(predictions['score'][0][1]) * 100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Delete our AutoML machine - we can import the project to any new Driverless AI machine, and the model will remain deployed to MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dai_engine.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
