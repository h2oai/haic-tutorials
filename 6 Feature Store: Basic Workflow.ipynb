{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Store - A unified storage of curated features\n",
    "\n",
    "This notebook is intended to help you get started with Feature Store in the H2O AI Cloud using python.\n",
    "\n",
    "* **Product Documentation:** https://docs.h2o.ai/feature-store/latest-stable/docs/index.html"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prerequistes\n",
    "\n",
    "Update the `h2o_ai_cloud.py` file with the connection parameters for your H2O AI Cloud environemnt:\n",
    "1. Login to your H2O AI Cloud environment\n",
    "1. Click your username or avatar in the H2O AI Cloud navigation bar\n",
    "1. Navigate to `CLI & API Access`\n",
    "1. Use the variables from the `Accessing H2O AI Cloud APIs` section to populate the parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from getpass import getpass\n",
    "\n",
    "from h2o_ai_cloud import token_provider, fs_client\n",
    "from featurestore import CSVFile, Schema\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Securely connect to the platform\n",
    "We first connect to the H2O AI Cloud using our platform token to create a token provider object. We can then use this object to log into Feature Store."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "client = fs_client(token_provider())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understand the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "client.get_version()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure spark for Feature Store "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.12.238,io.delta:delta-core_2.12:1.2.1\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define data source \n",
    "Feature Store supports different data sources - https://docs.h2o.ai/feature-store/latest-stable/docs/supported_data_sources.html"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "source = CSVFile(\"s3a://h2o-public-test-data/smalldata/gbm_test/titanic.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract schema from data source\n",
    "The schema represents the features of the feature set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "schema = client.extract_schema_from_source(source)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a project\n",
    "User can follow naming conventions mentioned in here - https://docs.h2o.ai/feature-store/latest-stable/docs/api/naming_conventions.html"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "project = client.projects.create(\"sample_project\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a feature set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "feature_set = project.feature_sets.register(schema, \"sample_fs\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ingest data from source\n",
    "Uploading data into Feature Store"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "feature_set.ingest(source)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "reference = feature_set.retrieve()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download features\n",
    "Download the files from Feature Store"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "reference.download()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain data as a Spark Frame \n",
    "Download features as spark dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "reference.as_spark_frame(spark).show()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare a schema from a string\n",
    "Schema can be created from a string format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "schema_str = \"id integer, value string\"\n",
    "schema = Schema.create_from(schema_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create another feature set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "fs_online = project.feature_sets.register(schema, \"sample_fs_online\", primary_key=\"id\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ingest data from Online Feature Store"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "fs_online.ingest_online('{\"id\": 1, \"value\": \"test\"}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieve data from Online Feature Store"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "fs_online.retrieve_online(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete a feature set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "fs_online.delete()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delete a project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "project.delete()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!rm "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.16 64-bit ('3.8.16': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "interpreter": {
   "hash": "b5803137338cb19a16337a87a205be3b478f8cca74095ec6d83bca1ed0847cec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}