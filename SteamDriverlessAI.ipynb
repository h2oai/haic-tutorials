{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bee925f-57bc-4728-a82e-824e39c216f9",
   "metadata": {},
   "source": [
    "# Steam to Driverless AI\n",
    "This notebook provides a getting started tutorial for how to securely connect to an instance of the H2O AI Cloud from a local workstation and then accomplish common tasks using Driverless AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a8104-117f-44bb-b036-a220b7bb3585",
   "metadata": {},
   "source": [
    "##### For more Driverless AI tutorials for more data science details go to: 'https://github.com/h2oai/driverlessai-tutorials/tree/master/dai_python_client'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9911e2-6f43-485d-93fa-bad60e53e27a",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "This tutorial relies on the latest Steam SDK which can be installed into a python environment using `pip install https://enterprise-steam.s3.amazonaws.com/release/1.8.11/python/h2osteam-1.8.11-py2.py3-none-any.whl`.\n",
    "\n",
    "This notebook was built on Steam version 1.8.9. If you are using a different version, there might be some differences in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267e3b10-1d31-4c2a-b3fe-e52489619d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import h2osteam\n",
    "import h2o_mlops_client as mlops\n",
    "from h2osteam.clients import DriverlessClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a731b-cb9d-4137-a28d-67bf3a5765bf",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Notebook-Setup\" data-toc-modified-id=\"Notebook-Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Notebook Setup</a></span></li><li><span><a href=\"#Securely-Connect\" data-toc-modified-id=\"Securely-Connect-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Securely Connect</a></span></li><li><span><a href=\"#AI-Engines\" data-toc-modified-id=\"AI-Engines-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>AI Engines</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-all-engines-I-own\" data-toc-modified-id=\"List-all-engines-I-own-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>List all engines I own</a></span></li></ul></li><li><ul class=\"toc-item\"><li><span><a href=\"#Create-new-instance\" data-toc-modified-id=\"Create-new-instance\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create new instance</a></span></li><li><span><a href=\"#add-a-dataset\" data-toc-modified-id=\"add-a-dataset-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Add a dataset</a></span></li><li><span><a href=\"#Run-an-experiment\" data-toc-modified-id=\"Run-an-experiment-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Run an experiment</a></span></li><li><span><a href=\"#Pause-our-instance\" data-toc-modified-id=\"Pause-the-instance-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Pause the instance</a></span></li><li><span><a href=\"#Resume-the-instance\" data-toc-modified-id=\"Resume-the-instance-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Resume the instance</a></span></li><li><span><a href=\"#Delete-the-instance\" data-toc-modified-id=\"Delete-the-instance-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Delete the instance</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca29d17-0dda-470e-b163-5f2bdd77eefc",
   "metadata": {},
   "source": [
    "## Securely Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b933e-da4b-47b3-807b-60a132f5aeb5",
   "metadata": {},
   "source": [
    "To get the personal access token, login to the Steam you would like to test with, click on configuration and then token. Copy and paste the token into the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35dd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_token = 'https://cloud-internal.h2o.ai/auth/get-platform-token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321f5cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click link to get personalized password: https://cloud-internal.h2o.ai/auth/get-platform-token\n",
      "········\n"
     ]
    }
   ],
   "source": [
    "print('Click link to get personalized password:', refresh_token)\n",
    "\n",
    "tp = mlops.TokenProvider(\n",
    "    token_endpoint_url = 'https://auth.demo.h2o.ai/auth/realms/q8s-internal/protocol/openid-connect/token',\n",
    "    client_id = 'q8s-internal-platform',\n",
    "    refresh_token=getpass.getpass()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab45a43-739a-4fbf-9438-92bfae2c46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam = h2osteam.login(\n",
    "    url=\"https://steam.cloud-internal.h2o.ai/\",\n",
    "    access_token=tp.ensure_fresh_token(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5a85d-cac2-4051-9e3f-e57b96e2cbf2",
   "metadata": {},
   "source": [
    "## AI Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff7f97",
   "metadata": {},
   "source": [
    "AI Engine is a tool that helps you build an AI system or machine learning model. These tools help to reiterate taks that repetitive and often difficult to achieve by a human. In this notebook, we are specifically looking at Driverless AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90eaaf",
   "metadata": {},
   "source": [
    "First lets check to see whether you have the same version of steam as the server version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b66f0",
   "metadata": {},
   "source": [
    "Server version of steam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a35d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': '1.8.11', 'build': '1.8.10-30-gaf0c13e-dirty', 'built': 'Thu Feb  3 00:05:06 UTC 2022', 'restart_pending': True, 'support_email': 'cloud-feedback@h2o.ai', 'license_valid': True, 'is_hadoop_enabled': False, 'is_kubernetes_enabled': True, 'is_h2o_enabled': True, 'is_h2o_running': True, 'is_sparkling_enabled': False, 'is_sparkling_running': False, 'is_driverless_enabled': True, 'is_driverless_running': True, 'is_h2o_engine_uploaded': False, 'is_h2o_kubernetes_engine_uploaded': True, 'is_sparkling_engine_uploaded': False, 'is_driverless_engine_uploaded': True, 'driverless_backend_type': 'kubernetes', 'is_minio_enabled': False, 'h2o_backend_type': 'kubernetes', 'inside_cluster': True}\n"
     ]
    }
   ],
   "source": [
    "print(h2osteam.api().get_config_meta())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91728eec",
   "metadata": {},
   "source": [
    "User version of steam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e02c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.11\n"
     ]
    }
   ],
   "source": [
    "print(h2osteam.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80d8d7-a80a-479a-a25d-3ae2af6f076c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List all Driverless AI instances I own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ffe24b-b4e0-4dec-85cf-b417b8799354",
   "metadata": {},
   "source": [
    "The following code lists all the available Driverless AI instances on steam and its attributes. Note that if you have not created an instance, nothing will show up on this list. Run this code again after you created an instance to see it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b007f0-c2ac-4253-8e00-5f2f63c6c50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dai_steam_instances = {}\n",
    "\n",
    "for dai_details in steam.get_driverless_instances():\n",
    "    dai_name = dai_details[\"name\"]\n",
    "    dai_status = dai_details[\"status\"]\n",
    "    \n",
    "    dai_steam_instances[dai_name] = dai_details\n",
    "                \n",
    "dai_steam_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d90a5-6ff2-4e9d-ac28-b63009d59cb4",
   "metadata": {},
   "source": [
    "### Create new instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057921d-7cc4-4abe-93aa-741c2a50b91e",
   "metadata": {},
   "source": [
    "In case we want to use a different version of Driverless AI, run the following line to see what versions are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2b64d9-deb4-4e29-8e24-565ee51cc8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'version': '1.9.0.6', 'major': 1, 'minor': 9, 'patch': 0, 'fix': 6},\n",
       " {'version': '1.9.1.1', 'major': 1, 'minor': 9, 'patch': 1, 'fix': 1},\n",
       " {'version': '1.9.1.3', 'major': 1, 'minor': 9, 'patch': 1, 'fix': 3},\n",
       " {'version': '1.9.2.1', 'major': 1, 'minor': 9, 'patch': 2, 'fix': 1},\n",
       " {'version': '1.9.3', 'major': 1, 'minor': 9, 'patch': 3, 'fix': 0},\n",
       " {'version': '1.10.0', 'major': 1, 'minor': 10, 'patch': 0, 'fix': 0},\n",
       " {'version': '1.10.1', 'major': 1, 'minor': 10, 'patch': 1, 'fix': 0},\n",
       " {'version': '1.10.1.1', 'major': 1, 'minor': 10, 'patch': 1, 'fix': 1},\n",
       " {'version': '1.10.1.2', 'major': 1, 'minor': 10, 'patch': 1, 'fix': 2},\n",
       " {'version': '1.10.1.3', 'major': 1, 'minor': 10, 'patch': 1, 'fix': 3}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2osteam.api().get_driverless_engines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abfc16",
   "metadata": {},
   "source": [
    "If you would like to use a different profile, run the following line to see what profiles are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d165402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Profile name: default-h2o\n",
      "Profile type: h2o\n",
      "Number of nodes: MIN=1 MAX=10\n",
      "CPUs per node: MIN=0 MAX=0\n",
      "YARN virtual cores: MIN=0 MAX=0\n",
      "Node memory [GB]: MIN=4 MAX=32\n",
      "Extra node memory [%]: MIN=10 MAX=200\n",
      "Max idle time [hrs]: MIN=1 MAX=24\n",
      "Max uptime [hrs]: MIN=1 MAX=24\n",
      "YARN queues: \n",
      "Start timeout [s]: MIN=60 MAX=600\n",
      "===\n",
      "Profile name: default-sparkling-internal\n",
      "Profile type: sparkling_internal\n",
      "Driver cores: MIN=1 MAX=8\n",
      "Driver memory [GB]: MIN=4 MAX=32\n",
      "Number of executors: MIN=1 MAX=10\n",
      "Executor cores: MIN=1 MAX=8\n",
      "Executor memory [GB]: MIN=4 MAX=32\n",
      "H2O threads per node: MIN=0 MAX=0\n",
      "Extra node memory [%]: MIN=0 MAX=200\n",
      "Max idle time [hrs]: MIN=1 MAX=24\n",
      "Max uptime [hrs]: MIN=1 MAX=24\n",
      "YARN queues: \n",
      "Start timeout: MIN=60 MAX=600\n",
      "===\n",
      "Profile name: default-sparkling-external\n",
      "Profile type: sparkling_external\n",
      "Driver cores: MIN=1 MAX=8\n",
      "Driver memory [GB]: MIN=4 MAX=32\n",
      "Number of executors: MIN=1 MAX=10\n",
      "Executor cores: MIN=1 MAX=8\n",
      "Executor memory [GB]: MIN=4 MAX=32\n",
      "H2O nodes: MIN=1 MAX=10\n",
      "H2O CPUs per node: MIN=0 MAX=0\n",
      "H2O node memory [GB]: MIN=4 MAX=32\n",
      "Extra node memory [%]: MIN=0 MAX=200\n",
      "Max idle time [hrs]: MIN=1 MAX=24\n",
      "Max uptime [hrs]: MIN=1 MAX=24\n",
      "YARN queues: \n",
      "Start timeout: MIN=60 MAX=600\n",
      "===\n",
      "Profile name: default-driverless-kubernetes\n",
      "Profile type: driverless_kubernetes\n",
      "===\n",
      "Profile name: se-driverless-kubernetes\n",
      "Profile type: driverless_kubernetes\n",
      "===\n",
      "Profile name: default-h2o-kubernetes\n",
      "Profile type: h2o_kubernetes\n"
     ]
    }
   ],
   "source": [
    "h2osteam.print_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe11d59-c6db-4d71-8221-4919b6acf6bf",
   "metadata": {},
   "source": [
    "This example hows how to create an instance of Driverless AI v1.10.0 and connect to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467bbdcd-a0e8-4061-a489-4d128d53d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driverless AI instance is submitted, please wait...\n",
      "Driverless AI instance is running\n"
     ]
    }
   ],
   "source": [
    "instance = DriverlessClient().launch_instance(name=\"test-instance\",\n",
    "                                              version=\"1.10.1.3\",\n",
    "                                              profile_name=\"default-driverless-kubernetes\")\n",
    "client = instance.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f914b7",
   "metadata": {},
   "source": [
    "If you want to interact with the UI, you can use this link!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "852d7472-a2c4-4f73-9b7f-9a250c5e691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><a href='https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331' rel='noopener noreferrer' target='_blank'>https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331</a></pre>"
      ],
      "text/plain": [
       "'https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.server.gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3558c20-1fa8-4047-8d4a-4881cebbc18a",
   "metadata": {},
   "source": [
    "### Add a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac2492-4d95-46e8-91e0-4f1d642885c6",
   "metadata": {},
   "source": [
    "To create a dataset on the Driverless AI server using data from an URL, include the URL and the name of the connecter used for data transfer, and set the dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a697ccf7-1157-4050-8931-37399be215ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 100.00% - [4/4] Computed stats for column Churn?\n"
     ]
    }
   ],
   "source": [
    "telco_churn = client.datasets.create(data=\"https://h2o-internal-release.s3-us-west-2.amazonaws.com/data/Splunk/churn.csv\", \n",
    "                                  data_source=\"s3\", \n",
    "                                  name=\"Telco_Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f24f6-c3f6-4673-b999-4d1be77b8c28",
   "metadata": {},
   "source": [
    "To create a dataset on the Driverless AI server using data on your local machine, first download the dataset onto a path on your local machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99bf72-c976-4ad2-8863-9883e407d0a7",
   "metadata": {},
   "source": [
    "To download a dataset to your local machine, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df73dd96-c11b-4b68-bdbd-8b7bb32de7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_location = '/Users/admin/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7ef7ae-4db0-43ed-856a-e1e3a5ce9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '/Users/admin/Downloads/churn.csv.1646077902.4344351.csv'\n"
     ]
    }
   ],
   "source": [
    "local_file_path = telco_churn.download(download_location, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898d0de-c82b-4599-8004-1dc87b9ea793",
   "metadata": {},
   "source": [
    "Then set the dataset name and create the dataset on the Driverless AI server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ba0607-15e1-449d-8f93-2ed72ecbba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete 100.00% - [4/4] Computed stats for column Churn?\n"
     ]
    }
   ],
   "source": [
    "telco_churn2 = client.datasets.create(local_file_path, name=\"Telco_Churn_Duplicate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336192b3-b4bd-409e-949f-4829e336c47f",
   "metadata": {},
   "source": [
    "To change the dataset name, simply run this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b875b74-080a-43f2-9443-6eeca515c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Name: Telco_Churn_Duplicate\n",
      "New Name: Telco Churn New Name\n"
     ]
    }
   ],
   "source": [
    "print(\"Old Name:\", telco_churn2.name)\n",
    "\n",
    "telco_churn2.rename(\"Telco Churn New Name\")\n",
    "\n",
    "print(\"New Name:\", telco_churn2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4afa3-139e-47d3-aaf8-55f6f3631d4b",
   "metadata": {},
   "source": [
    "### Run an experiment\n",
    "#### 1. First split the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5907c87f-f490-433a-98db-2e42e779de9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "telco_churn_split = telco_churn.split_to_train_test(\n",
    "    train_size=0.8, \n",
    "    train_name='telco_churn_train', \n",
    "    test_name='telco_churn_test', \n",
    "    target_column= \"Churn?\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd3cf83-dcad-4e86-b884-8599bcc45516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset': <class 'Dataset'> ecc456ce-98cf-11ec-8f6a-e670ca277224 telco_churn_train,\n",
       " 'test_dataset': <class 'Dataset'> ecc479ce-98cf-11ec-8f6a-e670ca277224 telco_churn_test}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_churn_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6263f5a-064e-43eb-8844-92a554aef95c",
   "metadata": {},
   "source": [
    "#### 2. Set up the experiment's settings (ie. accuracy, time, target column, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675321cd-0d72-4edc-8418-2504b8ea1a9f",
   "metadata": {},
   "source": [
    "You can list all existing experiments using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "430269e5-5ba8-43d0-b1cc-45846de2a9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.name for e in client.experiments.list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa5c60-e011-4a26-907a-9d8d7119530e",
   "metadata": {},
   "source": [
    "You might want to run several experiments with different dial and expert settings. All of these will likely have some things in common, namely details about this specific dataset. We will create a dictionary to use in many experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e302ea9-a050-4c95-8101-4548dce2e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_settings = {\n",
    "    **telco_churn_split,\n",
    "    'task': 'classification',\n",
    "    'target_column': \"Churn?\", \n",
    "    'scorer': 'F1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c100625-d12d-4052-a82d-cdcd970062a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY [7/10]:\n",
      "- Training data size: *2,666 rows, 20 cols*\n",
      "- Feature evolution: *[Constant, LightGBM, XGBoostGBM]*, *3-fold CV**, 2 reps*\n",
      "- Final pipeline: *Blend of up to 2 [Constant, LightGBM, XGBoostGBM] models, each averaged across 3-fold CV splits*\n",
      "\n",
      "TIME [2/10]:\n",
      "- Feature evolution: *8 individuals*, up to *10 iterations*\n",
      "- Early stopping: After *5* iterations of no improvement\n",
      "\n",
      "INTERPRETABILITY [8/10]:\n",
      "- Feature pre-pruning strategy: Permutation Importance FS\n",
      "- Monotonicity constraints: enabled\n",
      "- Feature engineering search space: [CVCatNumEncode, CVTargetEncode, Frequent, Interactions, NumCatTE, NumToCatWoEMonotonic, NumToCatWoE, Original, Text, WeightOfEvidence]\n",
      "- Pre-trained PyTorch NLP models (with fine-tuning): ['disabled']\n",
      "\n",
      "[Constant, LightGBM, XGBoostGBM] models to train:\n",
      "- Model and feature tuning: *48*\n",
      "- Feature evolution: *288*\n",
      "- Final pipeline: *6*\n",
      "\n",
      "Estimated runtime: *15 minutes*\n",
      "Estimated mojo_size: *2.6MB*\n",
      "Auto-click Finish/Abort if not done in: *1 day*/*7 days*\n"
     ]
    }
   ],
   "source": [
    "client.experiments.preview( # Get experiment preview with our settings\n",
    "    **telco_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fef044-7ee1-47e1-9baa-773de264ea47",
   "metadata": {},
   "source": [
    "There may be several common types of experiments you want to run, and H2O.ai will be creating common experiment settings in dictionaries for easy use. The one below turns off all extra settings such as building pipelines or checking for leakage. It also uses the fastest experiment settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eccb59d-4bbd-4e7e-99eb-33154130ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_settings = {\n",
    "    'accuracy': 1,\n",
    "    'time': 1,\n",
    "    'interpretability': 6,\n",
    "    'make_python_scoring_pipeline': 'off',\n",
    "    'make_mojo_scoring_pipeline': 'off',\n",
    "    'benchmark_mojo_latency': 'off',\n",
    "    'make_autoreport': False,\n",
    "    'check_leakage': 'off',\n",
    "    'check_distribution_shift': 'off'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871227c8-6a28-40cd-b286-f7d691a9da73",
   "metadata": {},
   "source": [
    "#### 3. Launch experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1e9ad2e-9a7a-4394-9bc7-42c96280116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment launched at: https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331/#/experiment?key=01c6ee7e-98d0-11ec-8f6a-e670ca277224\n"
     ]
    }
   ],
   "source": [
    "default_baseline = client.experiments.create_async( #comment out the other experiments that you dont want to run\n",
    "    **telco_settings, \n",
    "    #name='Fastest Settings', **fast_settings,\n",
    "    name='Default Baseline', accuracy=7, time=2, interpretability=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd3ef4-49b6-40ce-91ff-d5d89dd69959",
   "metadata": {},
   "source": [
    "#### 4. View information, summary, model artifacts, and model performance of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59a1ab01-e45b-423d-9d33-d69ab9397243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Default Baseline\n",
      "Datasets: {'train_dataset': <class 'Dataset'> ecc456ce-98cf-11ec-8f6a-e670ca277224 telco_churn_train, 'validation_dataset': None, 'test_dataset': <class 'Dataset'> ecc479ce-98cf-11ec-8f6a-e670ca277224 telco_churn_test}\n",
      "Target: Churn?\n",
      "Scorer: F1\n",
      "Task: classification\n",
      "Status: Complete 100.00% - Status: Complete\n",
      "Web Page: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><a href='https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331/#/experiment?key=01c6ee7e-98d0-11ec-8f6a-e670ca277224' rel='noopener noreferrer' target='_blank'>https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331/#/experiment?key=01c6ee7e-98d0-11ec-8f6a-e670ca277224</a></pre>"
      ],
      "text/plain": [
       "'https://steam.cloud-internal.h2o.ai:443/proxy/driverless/331/#/experiment?key=01c6ee7e-98d0-11ec-8f6a-e670ca277224'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prints information on experiment\n",
    "\n",
    "print(\"Name:\", default_baseline.name)\n",
    "print(\"Datasets:\", default_baseline.datasets)\n",
    "print(\"Target:\", default_baseline.settings['target_column']) # beta users from before March 15th use target_col\n",
    "print(\"Scorer:\", default_baseline.metrics()['scorer'])\n",
    "print(\"Task:\", default_baseline.settings['task'])\n",
    "print(\"Status:\", default_baseline.status(verbose=2))\n",
    "print(\"Web Page: \", end='')\n",
    "default_baseline.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38c29070-e219-40c0-b7ff-8ffa57e4ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Complete\n",
      "Experiment: Default Baseline (01c6ee7e-98d0-11ec-8f6a-e670ca277224)\n",
      "  Version: 1.10.1.2, 2022-02-28 19:58\n",
      "  Settings: 7/2/8, seed=393800133, GPUs disabled\n",
      "  Train data: telco_churn_train (2666, 21)\n",
      "  Validation data: N/A\n",
      "  Test data: [Test] (667, 20)\n",
      "  Target column: Churn? (binary, 14.479% target class)\n",
      "System specs: Docker/Linux, 28 GB, 32 CPU cores, 0/0 GPU\n",
      "  Max memory usage: 0.906 GB, 0 GB GPU\n",
      "Recipe: AutoDL (14 iterations, 8 individuals)\n",
      "  Validation scheme: stratified, 6 internal holdouts (3-fold CV)\n",
      "  Feature engineering: 40 features scored (19 selected)\n",
      "Timing: MOJO latency 0.0823 millis (1.7MB), Python latency 101.0092 millis (1.2MB)\n",
      "  Data preparation: 10.65 secs\n",
      "  Shift/Leakage detection: 3.66 secs\n",
      "  Model and feature tuning: 70.01 secs (55 models trained)\n",
      "  Feature evolution: 147.06 secs (126 of 288 models trained)\n",
      "  Final pipeline training: 29.68 secs (6 models trained)\n",
      "  Python / MOJO scorer building: 38.09 secs / 22.29 secs\n",
      "Validation score: F1 = 0.2529489 (constant preds of -1.776)\n",
      "Validation score: F1 = 0.7722271 +/- 0.02724926 (baseline)\n",
      "Validation score: F1 = 0.7703179 +/- 0.02596586 (final pipeline)\n",
      "Test score:       F1 = 0.7608696 +/- 0.03247189 (final pipeline)\n"
     ]
    }
   ],
   "source": [
    "#view experiment summary\n",
    "\n",
    "default_baseline.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6184ad31-cacb-4083-bb8a-b0a361d0de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available artifacts: ['autodoc', 'logs', 'mojo_pipeline', 'python_pipeline', 'summary', 'test_predictions', 'train_predictions']\n"
     ]
    }
   ],
   "source": [
    "#see what model artifacts are available\n",
    "\n",
    "print(\"Available artifacts:\", default_baseline.artifacts.list()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81a28d98-f63f-4933-a84c-ebd47f6c0d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating autodoc...\n"
     ]
    }
   ],
   "source": [
    "#generate autodoc\n",
    "\n",
    "default_baseline.artifacts.create('autoreport') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "514e07f2-6223-432e-910f-f085c7eb3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '/Users/admin/Downloads/report.docx'\n"
     ]
    }
   ],
   "source": [
    "#download autodoc\n",
    "\n",
    "artifacts = default_baseline.artifacts.download(['autoreport'], download_location, overwrite=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e0d890f-f973-48f4-a04f-251b1db2b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OSX - open autodoc on MacOS\n",
    "\n",
    "!open -a \"Microsoft Word\" {artifacts[\"autoreport\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbedb324-88d0-45b8-9024-b2b1ef3b8ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scorer': 'F1',\n",
       " 'val_score': 0.770317916991267,\n",
       " 'val_score_sd': 0.02596585550001304,\n",
       " 'val_roc_auc': 0.9067638329415454,\n",
       " 'val_pr_auc': 0.7882773719648645,\n",
       " 'test_score': 0.7608695652173914,\n",
       " 'test_score_sd': 0.03247189403885633,\n",
       " 'test_roc_auc': 0.9001266051727257,\n",
       " 'test_pr_auc': 0.7703275526356188}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view final model performance\n",
    "\n",
    "default_baseline.metrics() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b31af-224a-4382-838c-9204833e9d75",
   "metadata": {},
   "source": [
    "### Pause the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4b2d7",
   "metadata": {},
   "source": [
    "You can pause an instance that is currently running. Pausing an instance shuts it down, it is similar to powering off a server. You will not loose any data and you can start an instance at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7265890-77b3-4a57-b49c-4b27b5917d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driverless AI instance is stopping, please wait...\n",
      "Driverless AI instance is stopped\n"
     ]
    }
   ],
   "source": [
    "instance.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f2b57-b698-43e0-89e5-83d5fc61da73",
   "metadata": {},
   "source": [
    "### Resume the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98ab5a",
   "metadata": {},
   "source": [
    "You can resume a paused instance by simply running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a256ded-a1c5-4f31-9146-1e960661a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driverless AI instance is starting, please wait...\n",
      "Driverless AI instance is running\n"
     ]
    }
   ],
   "source": [
    "instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a844a-422e-435d-a430-de55fd0c5328",
   "metadata": {},
   "source": [
    "### Delete the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85762776",
   "metadata": {},
   "source": [
    "When you no longer need an instance, you can terminate it. Once deleted, there is no way to restart the instance or access any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1500c6d-473f-4495-9e9f-da19be4f57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
